{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939274a1-20fe-42e1-b2db-1834c4b9e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from urllib.parse import urlparse, unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46643c11-4223-4939-bb38-5bee7a2febdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    \"\"\"Set up logging to file.\"\"\"\n",
    "    logging.basicConfig(filename='geo_boundaries_errors.log', level=logging.ERROR,\n",
    "                        format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "def fetch_data(url):\n",
    "    \"\"\"Fetch data from the provided URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_geojson(url, folder_path):\n",
    "    \"\"\"Download and save the GeoJSON file, keeping the original file name from the URL.\"\"\"\n",
    "    try:\n",
    "        file_name = unquote(urlparse(url).path.split('/')[-1])\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(response.text)\n",
    "\n",
    "        print(f\"Successfully downloaded and saved {file_name}\")\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch or save GeoJSON for {file_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "def manage_geoboundaries_retrieval(adm_level, delay=3):\n",
    "    setup_logging()\n",
    "    \n",
    "    base_url = f\"https://www.geoboundaries.org/api/current/gbOpen/ALL/{adm_level}/\"\n",
    "    folder_name = \"country-geojson\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    print(f\"Fetching data from {base_url}\")\n",
    "    data = fetch_data(base_url)\n",
    "    \n",
    "    if data:\n",
    "        for item in data:\n",
    "            simplified_geojson_url = item['simplifiedGeometryGeoJSON']\n",
    "            print(f\"Downloading GeoJSON from {simplified_geojson_url}\")\n",
    "            download_geojson(simplified_geojson_url, folder_name)\n",
    "            \n",
    "            # Wait for 3 seconds before making the next API call\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf9f046-def9-4bf6-8128-544332f73c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage_geoboundaries_retrieval(\"ADM2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fac39bf7-cc73-40d2-8677-9775fc525789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_geojson_files(directory_path):\n",
    "    return [f for f in os.listdir(directory_path) if f.endswith('.geojson')]\n",
    "\n",
    "\n",
    "def separate_files_by_adm_level(geojson_files, directory_path):\n",
    "    countries = {}\n",
    "    adm1_subareas = {}\n",
    "    adm2_subareas = {}\n",
    "\n",
    "    for file in geojson_files:\n",
    "        if 'ADM0' in file:\n",
    "            iso_code = file.split('-')[1]\n",
    "            countries[iso_code] = os.path.join(directory_path, file)\n",
    "        elif 'ADM1' in file:\n",
    "            iso_code = file.split('-')[1]\n",
    "            if iso_code not in adm1_subareas:\n",
    "                adm1_subareas[iso_code] = []\n",
    "            adm1_subareas[iso_code].append(os.path.join(directory_path, file))\n",
    "        elif 'ADM2' in file:\n",
    "            iso_code = file.split('-')[1]\n",
    "            if iso_code not in adm2_subareas:\n",
    "                adm2_subareas[iso_code] = []\n",
    "            adm2_subareas[iso_code].append(os.path.join(directory_path, file))\n",
    "    \n",
    "    return countries, adm1_subareas, adm2_subareas\n",
    "\n",
    "\n",
    "def process_adm_files(adm_files, subareas):\n",
    "    subarea_list = []\n",
    "    for adm_path in adm_files:\n",
    "        with open(adm_path, 'r', encoding='utf-8') as sub_file:\n",
    "            sub_data = json.load(sub_file)\n",
    "            for sub_feature in sub_data['features']:\n",
    "                sub_isocode = sub_feature['properties'].get('shapeISO')\n",
    "                sub_name = sub_feature['properties'].get('shapeName')\n",
    "                sub_id = sub_feature['properties'].get('shapeID')\n",
    "                if sub_name:\n",
    "                    subarea_list.append({\n",
    "                        'isocode': sub_isocode,\n",
    "                        'name': sub_name,\n",
    "                        'id': sub_id\n",
    "                    })\n",
    "    return subarea_list\n",
    "\n",
    "\n",
    "def process_countries(countries, adm1_subareas, adm2_subareas):\n",
    "    country_list = []\n",
    "    missing_countries = []\n",
    "\n",
    "    for iso_code, path in countries.items():\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            valid_entry = False\n",
    "            for feature in data['features']:\n",
    "                country_isocode = feature['properties'].get('shapeISO')\n",
    "                country_name = feature['properties'].get('shapeName')\n",
    "                if country_isocode and country_name:\n",
    "                    valid_entry = True\n",
    "                    country_entry = {\n",
    "                        'isocode': country_isocode,\n",
    "                        'name': country_name,\n",
    "                        'adm1_subareas': process_adm_files(adm1_subareas.get(iso_code, []), 'adm1'),\n",
    "                        'adm2_subareas': process_adm_files(adm2_subareas.get(iso_code, []), 'adm2')\n",
    "                    }\n",
    "                    country_list.append(country_entry)\n",
    "\n",
    "            if not valid_entry:\n",
    "                missing_countries.append({\n",
    "                    'filename': os.path.basename(path),\n",
    "                    'reason': 'Invalid ADM0 file content'\n",
    "                })\n",
    "    \n",
    "    return country_list, missing_countries\n",
    "\n",
    "\n",
    "def process_missing_countries(adm1_subareas, adm2_subareas, existing_countries):\n",
    "    missing_countries = []\n",
    "\n",
    "    for iso_code, adm1_files in adm1_subareas.items():\n",
    "        if iso_code not in existing_countries:\n",
    "            country_entry = {\n",
    "                'isocode': iso_code,\n",
    "                'name': 'Unknown',\n",
    "                'adm1_subareas': process_adm_files(adm1_files, 'adm1'),\n",
    "                'adm2_subareas': process_adm_files(adm2_subareas.get(iso_code, []), 'adm2')\n",
    "            }\n",
    "            missing_countries.append(country_entry)\n",
    "    \n",
    "    return missing_countries\n",
    "\n",
    "\n",
    "def write_json_files(country_list, missing_countries):\n",
    "    with open('countries.json', 'w') as file:\n",
    "        json.dump(country_list, file, indent=4)\n",
    "\n",
    "    with open('missing_countries.json', 'w') as file:\n",
    "        json.dump(missing_countries, file, indent=4)\n",
    "\n",
    "\n",
    "def create_country_list_json(directory_path='country-geojson'):\n",
    "    geojson_files = list_geojson_files(directory_path)\n",
    "    countries, adm1_subareas, adm2_subareas = separate_files_by_adm_level(geojson_files, directory_path)\n",
    "    \n",
    "    country_list, initial_missing_countries = process_countries(countries, adm1_subareas, adm2_subareas)\n",
    "    additional_missing_countries = process_missing_countries(adm1_subareas, adm2_subareas, countries)\n",
    "    \n",
    "    missing_countries = initial_missing_countries + additional_missing_countries\n",
    "    \n",
    "    write_json_files(country_list, missing_countries)\n",
    "\n",
    "    print(f\"Number of countries: {len(country_list)}\")\n",
    "    print(f\"Number of missing entries: {len(missing_countries)}\")\n",
    "\n",
    "    return 'country_list.json', 'missing_countries.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ae9242d-4e28-4e4e-86f6-359c0bf014fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 230\n",
      "Number of missing entries: 0\n",
      "Data has been successfully saved to country_list.json\n",
      "Missing countries have been saved to missing_countries.json\n"
     ]
    }
   ],
   "source": [
    "output_file, missing_file = create_country_list_json()\n",
    "print(f\"Data has been successfully saved to {output_file}\")\n",
    "print(f\"Missing countries have been saved to {missing_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e93a60-b626-4510-aad9-2f4e4c496b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
